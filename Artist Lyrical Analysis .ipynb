{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#          Imports          #\n",
    "#############################\n",
    "\n",
    "import os\n",
    "import json\n",
    "import spotipy\n",
    "import numpy as np\n",
    "import spotipy.util as util\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from json.decoder import JSONDecodeError\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully authenticated\n"
     ]
    }
   ],
   "source": [
    "#setting up some of the needed objects for Spotify API\n",
    "username = 'xxxxxx'\n",
    "my_client_id = 'xxxxxx'\n",
    "my_secret = 'xxxxxx'\n",
    "my_redirect_uri = 'xxxxxx'\n",
    "spotify = spotipy.Spotify()\n",
    "scope = 'user-library-read'\n",
    "\n",
    "#User permission\n",
    "try:\n",
    "    token = util.prompt_for_user_token(username, scope, my_client_id,\n",
    "                                       my_secret, redirect_uri = my_redirect_uri)\n",
    "except:\n",
    "    os.remove(f\".cache-{username}\")\n",
    "    token = util.prompt_for_user_token(username)\n",
    "    \n",
    "#getting authorization\n",
    "if token:\n",
    "    spotify_object = spotipy.Spotify(auth = token)\n",
    "    print('Successfully authenticated')\n",
    "else:\n",
    "    print('Cannot get token for', username)\n",
    "\n",
    "#saving user as an object\n",
    "user = spotify_object.current_user()\n",
    "\n",
    "#obtaining display name and follower count values for printing purposes\n",
    "displayName = user['display_name']\n",
    "follower_count = user['followers']['total']\n",
    "artist_name =  'Frank Ocean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Hello Yoon Sung Hong!\n",
      "Artist Name:  Frank Ocean\n",
      "Genres: hip hop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Hello \" + displayName + \"!\")\n",
    "search_results = spotify_object.search(artist_name, 1, 0, \"artist\")\n",
    "artist = search_results['artists']['items'][0]\n",
    "print('Artist Name: ',artist['name'])\n",
    "print('Genres:',artist['genres'][0])\n",
    "#print('Genres:',artist['genres'][0].replace(' ', ', '))\n",
    "print()\n",
    "artistID = artist['id']\n",
    "\n",
    "#albums and tracks\n",
    "trackURIs = []\n",
    "\n",
    "album_results = spotify_object.artist_albums(artistID)\n",
    "album_results = album_results['items']\n",
    "\n",
    "for album in album_results:\n",
    "    albumID = album['id']\n",
    "    #extracting tracks\n",
    "    track_results = spotify_object.album_tracks(albumID)\n",
    "    track_results = track_results['items']\n",
    "    #nested iteration to add track uri to master list\n",
    "    for song in track_results:\n",
    "        #only appending songs where the artist is the main singer; i.e. first person listed as the artist, not feature\n",
    "        if (artist_name in song['artists'][0]['name']):\n",
    "            trackURIs.append(song['uri'])\n",
    "    \n",
    "    #if you want to include artists' collaborations and features, uncomment\n",
    "    #for song in track_results:\n",
    "        #for song_artist in song['artists']:\n",
    "            #if song_artist['name'] == artist_name:\n",
    "                #trackURIs.append(song['uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#With Track URIs, getting song names\n",
    "#Initializing trackNames list\n",
    "trackNames = []\n",
    "for URI in trackURIs:\n",
    "    track = spotify_object.track(URI)\n",
    "    trackNames.append(track['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Using the Genius API  #\n",
    "#########################\n",
    "YOUR_CLIENT_ID = 'xxxxxx'\n",
    "genius_token = 'xxxxxx'\n",
    "base_url = \"http://api.genius.com\"\n",
    "search_url = base_url + \"/search\"\n",
    "headers = {'Authorization': 'Bearer ' + genius_token}\n",
    "def get_song_info(url, list_songs, headers):\n",
    "    songs = []\n",
    "    for song in list_songs:\n",
    "        data = {'q': song}\n",
    "        response = requests.get(url, params=data, headers=headers)\n",
    "        json = response.json()\n",
    "        #initializing song info\n",
    "        song_info = None\n",
    "        for hit in json[\"response\"][\"hits\"]:\n",
    "            #verifying the search result and its artist is the same as the artist of our choice (i.e. Frank Ocean)\n",
    "            if hit[\"result\"][\"primary_artist\"][\"name\"] == artist_name:\n",
    "                song_info = hit\n",
    "                break\n",
    "        if song_info:\n",
    "            #verifying that the song exists in Genius. If it exists, adds on to the list.\n",
    "            songs.append(song_info)\n",
    "    return songs\n",
    "songs = get_song_info(search_url, trackNames, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the genius urls for all songs\n",
    "#initializing a dictionary\n",
    "url_dict = {}\n",
    "genius_url = []\n",
    "for song in songs:\n",
    "    url_extension = song['result']['path']\n",
    "    url = 'https://genius.com' + url_extension\n",
    "    genius_url.append(url)\n",
    "    url_dict[song['result']['title']] = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting lyrics\n",
    "lyrics_dict = {}\n",
    "for URL in genius_url:\n",
    "    page = requests.get(URL)\n",
    "    html = BeautifulSoup(page.text, \"html.parser\") # Extract the page's HTML as a string\n",
    "    # Scrape the song lyrics from the HTML\n",
    "    lyrics = html.find(\"div\", class_=\"lyrics\").get_text()\n",
    "    lyrics_dict[URL] = lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['these', 'bitches', 'want', ..., 'good', 'don’t', 'die'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing every alphabet for later purposes\n",
    "english = \"a b c d e f g h i j k l m n o p q r s t u v w x y z A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\".split()\n",
    "#initializing an array\n",
    "master_array = np.array([])\n",
    "#initializing a master string for later purposes\n",
    "master_string = \"\"\n",
    "#initializing a dictionary for unique words count for each song (to be used in exploratory analysis later)\n",
    "song_unique_dict = {}\n",
    "#iterating through each song (and its URL) and using regex expression to clean the lyrics data\n",
    "for URL in genius_url:\n",
    "    pretty = lyrics_dict[URL].replace('\\n', ' ')\n",
    "    pretty = re.sub(r'\\[.*?\\]', '', pretty)\n",
    "    pretty = re.sub(r'\\s+', ' ', pretty)\n",
    "    pretty = re.sub(r'\"', '', pretty)\n",
    "    pretty = re.sub(r'\\(', '', pretty)\n",
    "    pretty = re.sub(r'\\)', '', pretty)\n",
    "    pretty = re.sub(r',', '', pretty)\n",
    "    pretty = re.sub(r'\\?', '', pretty)\n",
    "    pretty = re.sub(r\"(you\\'.+?.)\", '', pretty) #regex format to filter out you've, you'll, etc.\n",
    "    pretty = pretty.replace('\\'', '’')\n",
    "    word_list = pretty.lower().split()\n",
    "    #filtering only english lyrics (one of the songs, Nikes, contains Japanese lyrics)\n",
    "    is_english = [word[0] in english for word in word_list] \n",
    "    word_list = np.array(word_list)\n",
    "    #recording the number of unique words used per song \n",
    "    song_unique_dict[URL] = len(np.unique(word_list)) #may exclude some of the stop words\n",
    "    #appending the song lyrics to master array \n",
    "    master_array = np.append(master_array, word_list)\n",
    "#checking if the words are stopwords\n",
    "is_stopword = (np.isin(master_array, stopwords.words('english')) == False)\n",
    "#subsetting only those words that are not stopwords(according to nltk pkg)\n",
    "master_array = master_array[is_stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(master_array, return_counts=True)\n",
    "word_count = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2760"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the dictionary in descending order of word counts\n",
    "word_count_ordered = []\n",
    "for i in sorted(word_count, key=word_count.get, reverse=True):\n",
    "    word_count_ordered.append(i + \": \" + str(word_count[i]))\n",
    "#number of different words used\n",
    "len(word_count_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average number of unique words used\n",
    "unique_mean = np.mean(list(song_unique_dict.values()))\n",
    "#maximum number of unique words used\n",
    "unique_max = np.max(list(song_unique_dict.values()))\n",
    "print(\"Average # of words:\", unique_mean, \"| \"\n",
    "     \"Maximum # of words:\", unique_max)\n",
    "#distribution of unique words used in each song\n",
    "sns.distplot(list(song_unique_dict.values()), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of the word count (number of times a word was used in all Frank Ocean's songs)\n",
    "sns.distplot(list(word_count.values()), bins = 10) #excludes stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new unique words count dictionary, but with song title instead of URL as key this time\n",
    "song_unique_dict_new = {'song title': list(url_dict.keys()), 'unique words count': list(song_unique_dict.values())}\n",
    "#converting dictionary into data frame\n",
    "song_unique_df = pd.DataFrame(data = song_unique_dict_new)\n",
    "#ordering the data frame by unique words count, descending. displaying first 20 songs\n",
    "song_unique_df.sort_values(by='unique words count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#  Named Entity Recognition #\n",
    "#############################\n",
    "#using stanford's NER tool\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "st = StanfordNERTagger('/Users/yoonsunghong/stanford-corenlp/stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "               '/Users/yoonsunghong/stanford-corenlp/stanford-ner/stanford-ner.jar')\n",
    "#st.tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
